{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selekcja cech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W ramach ćwiczenia będą stosowane kryteria oceny cech opisujących dokumenty ze zbioru `fetch20newsgroups` z punktu widzenia zadania klasyfikacji. Do eksperymentów wybierz dokumenty z kilku grup dyskusyjnych, które będą stanowiły poszczególne klasy (wybrane kategorie należy odkomentować)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "categories = [\n",
    "    #'alt.atheism',\n",
    "    'comp.graphics',\n",
    "    #'comp.os.ms-windows.misc',\n",
    "    #'comp.sys.ibm.pc.hardware',\n",
    "    #'comp.sys.mac.hardware',\n",
    "    #'comp.windows.x',\n",
    "    #'misc.forsale',\n",
    "    'rec.autos',\n",
    "    #'rec.motorcycles',\n",
    "    #'rec.sport.baseball',\n",
    "    #'rec.sport.hockey',\n",
    "    #'sci.crypt',\n",
    "    #'sci.electronics',\n",
    "    #'sci.med',\n",
    "    'sci.space',\n",
    "    #'soc.religion.christian',\n",
    "    'talk.politics.guns',\n",
    "    #'talk.politics.mideast',\n",
    "    #'talk.politics.misc',\n",
    "    #'talk.religion.misc'\n",
    "]\n",
    "dataset = fetch_20newsgroups(subset='all', categories = categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Liczba zaladowanych dokumentow wynosi \", len(dataset.data))\n",
    "print(\"Naleza one do jednej z \", len(dataset.target_names), \" kategorii.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przykładowa wiadomość z wczytanego zbioru wygląda następująco:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_number = 5\n",
    "print(\"Przykladowa wiadomosc z grupy \", dataset.target_names[dataset.target[doc_number]])\n",
    "dataset.data[doc_number]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Każdy dokument będzie reprezentowany przez wektor cech, którego składowe są wagami dla słów branych pod uwagę w analizowanym zbiorze dokumentów. Do wyznaczenia tych wektorów cech służy klasa `TfidfVectorizer`. \n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer\n",
    "\n",
    "Liczba cech opisujących dokumenty może być równa, w skrajnym przypadku, liczbie wszystkich słów występujących we wszystkich dokumentach w zbiorze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, min_df=2, max_features = None, stop_words='english')\n",
    "docs_vectors = vectorizer.fit_transform(dataset.data)\n",
    "print(\"Liczba dokumentów: \", docs_vectors.shape[0])\n",
	"print(\"Liczba cech: \", docs_vectors.shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dla danego dokumentu składowa i-ta tego wektora cech to liczba wystąpień i-tego słowa (cechy) w tym dokumencie pomnożona przed  współczynni idf, który zależy od całkowitej liczby dokumentów w zbiorze oraz liczby dokumentów zawierającyh słowo i-te. Szczegółowy opis wyznaczania tych cech można znaleźć w dokumentacji \n",
    "http://scikit-learn.org/stable/modules/feature_extraction.html\n",
    "Wektor wartości idf dla wszystkich słów (cech) można odczytać w następujący sposób:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.idf_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metoda `get_feature_names_out` pozwala na odczytanie nazw wszystkich cech, czyli słów branych pod uwagę podczas analizowania zbioru dokumentów. Są one posortowane alfabetycznie. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = vectorizer.get_feature_names_out()\n",
    "terms[-20:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podział zbioru na dane uczące i testowe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data_train, data_test, target_train, target_test = train_test_split(docs_vectors, dataset.target, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uczenie klasyfikatora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "tree = tree.DecisionTreeClassifier()\n",
    "tree.fit(data_train, target_train)\n",
    "print(\"Blad klasyfikacji dla danych testowych wynosi: \", 1.0 - tree.score(data_test,target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do selekcji cech można wykorzystać klasę `SelectKBest` pozwalającą na ocenę cech na podstawie wybranej miary podanej jako parametr. \n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectKBest.html#sklearn.feature_selection.SelectKBest\n",
    "\n",
    "Po wywołaniu metody `fit` zostaną obliczone wartości miary dla wszystkich cech. Można je odczytać z atrybutu `scores_`.\n",
    "\n",
    "Metoda `transform` przekształca zbiór danych zostawiając tylko zadaną liczbę cech o najwyższych wartościach.\n",
    "\n",
    "Metoda `fit_transform` ocenia cechy a następnie przekształca zbiór danych (efekt jak po zastosowaniu kolejno `fit` oraz `transform`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "select_mutual = SelectKBest(chi2,k=20)\n",
    "select_mutual.fit(data_train, target_train)\n",
    "select_mutual.scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 1 (2 pkt.)**\n",
    "\n",
    "Zmodyfikuj zbiór danych zostawiając N cech o największych wartościach miary chi2. Przeprowadź uczenie i testowanie drzewa po tej modyfikacji. Czy redukcja liczby cech wpłynęła na zmianę błędu klasyfikacji? Przeprowadź próby przynajmniej dla 5 różnych wartości N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 2 (1 pkt.)**\n",
    "\n",
    "Wyświetl 30 słów odpowiadających cechom o największych wartościach miary chi2. Czy widać ich związek z wybranymi klasami (kategoriami)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ekstrakcja cech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jedną z podstawowych metod ekstrakcji cech jest analiza głównych składowych (ang. principal component analysis - PCA) zaimplementowana w klasie `PCA`. Podstawowym parametrem metody jest parametr `n_components` decydujcy o liczbie cech po transformacji.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA\n",
    "digits = load_digits(n_class=10)\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "n_samples, n_features = X.shape\n",
    "pca = PCA(n_components = 2)\n",
    "X_new = pca.fit_transform(X)\n",
    "plt.scatter(X_new[:,0], X_new[:,1],c=y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inną metodą ekstrakcji jest liniowa analiza dyskryminacyjna, która w przeciwieństwie do PCA uwzględnia informację o przynależności danych do poszczególnych klas.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda = LinearDiscriminantAnalysis(n_components=2)\n",
    "X_lda = lda.fit_transform(X, y)\n",
    "plt.scatter(X_lda[:,0], X_lda[:,1], c=y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 3 (1,5 pkt.)**\n",
    "\n",
    "Dla danych `digits` przeprowadź analizę głównych składowych i narysuj tzw. wykres osypiska, czyli wykres pokazujący wartości wariancji dla kolejnych składowych głównych. Wykres powinien być narysowany dla wszystkich składowych. Wartości wariancji można odczytać z atrybutu `pca.explained_variance_ratio_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 4 (1,5 pkt.)**\n",
    "\n",
    "Napisz funkcję, która zwraca liczbę cech, jakie należy uwzględnić, aby zachować po przeprowadzeniu analizy głównych składowych część wariancji (suma wariancji związanych z poszczególnymi składowymi) podaną jako parametr funkcji. Parametr ten może przyjmować wartości z przedziału (0;1]. Jesli jako parametr wejściowy podano wartość 1, co oznacza 100% wariancji, funkcja powinna zwrócić maksymalną liczbą cech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 5 (1,5 pkt)**\n",
    "\n",
    "Zredukuj liczbę cech wybranego zbioru danych stosując analizę głównych składowych. O ostatecznej liczbie cech zdecyduj na podstawie ilości zachowanej wariancji. Przeprowadź uczenie i testowanie wybranego klasyfikatora na tych danych.\n",
    "\n",
    "Uwaga 1: liczba cech po transformacji będzie równa wartości `n_components` lub liczbie przykładów w zbiorze jeśli jest ich mniej niż `n_components`.\n",
    "\n",
    "Uwaga 2: analiza głownych składowych powinna być przeprowadzona na podstawie danych uczących, natomiast dane testowe powinny być przetworzone na podstawie macierzy transformacji otrzymanej w wyniku przeprowadzenia PCA na danych uczących. Odpowiedz na pytanie, dlaczego zastosowanie PCA na pełnym zbiorze danych (uczące + testowe) jest niewłaściwe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 6 (1 pkt.)**\n",
    "\n",
    "Wykonaj analogiczne zadanie stosując wybraną metodę selekcji cech zamiast analizy głównych składowych. Porówaj wyniki zwracając uwagę na to, ile cech należy wybrać, aby otrzymać wynik na poziomie takim, jak otrzymano w zadaniu 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Dobór optymalnych wartości parametrów\n",
    "\n",
    "Klasa `GridSearchCV` umożliwia przeprowadzenie uczenia modelu i testowania dla różnych parametrów i wybór zestawu parametrów optymalnych z punktu widzenia danego kryterium (np. w przypadku klasyfikatorów tym kryterium jest minimalny błąd klasyfikacji). Testowanie modelu dla różnych wartości parametrów odbywa się w procesie walidacji krzyżowej.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "W poniższym przykładzie uczone będzie drzewo decyzyjne (dla danych `digits`) dla różnych kryteriów wyboró atrybutu oraz różnych wartości minimalnej liczby przykładów w liściach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix #, accuracy_score\n",
    "data_train, data_test, target_train, target_test = train_test_split(digits.data, digits.target, test_size=0.3, random_state=0)\n",
    "tree = DecisionTreeClassifier()\n",
    "parameters ={'criterion': ['gini', 'entropy'], 'min_samples_leaf': [5,4,3]}\n",
    "search = GridSearchCV(tree, parameters, cv=5)\n",
    "search.fit(data_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wartości parametrów, dla których osiągnięto najlepszy wynik są zapisane w atrybucie `best_params_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przetestowanie modelu dla najlepszego zestawu parametrów."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.score(data_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Przetwarzanie potokowe\n",
    "\n",
    "Jeżeli nasz proces składa się z kilku etapów można wykorzystać klasę `Pipeline`.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "\n",
    "W poniższym przykładzie zdefiniowano proces składający się z ekstaraktora cech (PCA) oraz klasyfikatora (drzewo decyzyjne)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipe = Pipeline([('extract', PCA()), ('classify', DecisionTreeClassifier())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przetwarzanie potokowe zwykle łączy się z poszukiwaniem optymalnego zestawu parametrów. Jako parametr funkcji `GridSearchCV` należy wtedy podać obiekt reprezentujący nasz wieloetapowy proces. W przykładzie poniżej dla zdefiniowanego potoku odbywa się poszukiwanie optymalnej wartości liczby składowych dl ametody PCA. Nazwy prametrów tworzy się łącząc nadaną przez nas nazwę etapu (`extract`) z nazwą odpowiedniego parametru (`n_components`) za pomocą znaków podkreślenia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'extract__n_components': [10,20,30]}\n",
    "search = GridSearchCV(pipe, parameters, cv=5)\n",
    "search.fit(data_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.score(data_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zadanie 7 (1,5 pkt.)**\n",
    "\n",
    "Dla wybranego zbioru danych zaprojektuj model składający się z etapu selekcji cech, ekstrakcji cech i klasyfikacji. Optymalne parametry selekcji i ekstrakcji dobierz korzystając z klasy `GridSearchCV`. Możesz wybrać dowolny klasyfikator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}